\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry} 
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{mathtools}
\usepackage{titlesec}

\titleformat*{\section}{\large\bfseries}

\begin{document}

\begin{center}
    {\LARGE Parallel matrix multiplication using MPI} \\[0.6cm]

    Lee Kai Yang (23205838) \\
    \texttt{\small kai.y.lee@ucdconnect.ie} \\[0.3cm]

    \small December 6, 2023
\end{center}

\begin{section}{Introduction}
 The aim of this experiment is to discover the difference between serial and parallel algorithm for computing matrix multiplication. The
 parallel algorithm used in this experiemnt was imlemented using \textbf{Message Passing Interface (MPI)} and the benchmark  was ran on a machine with 8 x Intel(R) Xeon(R) E5-2620 v3 @ 2.40GHz processors.
 Hence, all the benchmark for the parallel algorithm is ran with 8 processes meaning they are ran with \texttt{mpirun -np 8}.

 All the matrix multiplication algorithms used in this experiment were manually written without using any third-party dependencies both for
 the serial and the parallel algorithm.
\end{section}

\begin{section}{Dependence of program execution time on matrix size}
 Since the matrix size $n$ must be divisible by the number of processes, the benchmark was ran with $n$ ranging from
 $256$ to $4096$ with a step of $256$. Figures below show the execution time for the serial and parallel algorithm with
 increasing matrix size $n$.

 \begin{center}
     %  \begin{minipage}{0.48\linewidth}
     %      \includegraphics*[width=8cm]{images/benchmark_serial_multiplication.png}
     %      \captionof{figure}{Matrix multiplication with serial algorithm}
     %  \end{minipage}
     \begin{minipage}{0.48\linewidth}
         \includegraphics*[width=8cm]{images/benchmark_parallel_mpi.png}
         \captionof{figure}{Matrix multiplication with parallel algorithm}
     \end{minipage}
 \end{center}

 From the results above, we can deduce that as matrix size $n$ increases, execution time increases. This is true for both cases because
 the number of computation needed increases.

\end{section}

\pagebreak

\begin{section}{Speedup of parallel algorithm over serial algorithm}
 To further investigate on the speedup of the parallel algorithm over the serial algorithm, Figure 3 below shows the plot of the execution time
 for the serial algorithm and the parallel algorithm on the same graph. Moreover, Table 1 below includes the execution time for both algorithms
 for different matrix size $n$.

 \begin{center}
     \includegraphics*[width=12cm]{images/benchmark_combined.png}
     \captionof{figure}{Matrix norm benchmark}
 \end{center}

 \begin{center}
     \begin{tabular}{|c | c | c|}
         \hline
         \textbf{Matrix size (n)} & \textbf{Time taken for serial (ms)} & \textbf{Time taken for parallel (ms)} \\ [0.5ex]
         \hline
         256                      & 48.62                               & 8.54                                  \\
         \hline
         512                      & 173.62                              & 45.76                                 \\
         \hline
         758                      & 566.35                              & 107.89                                \\
         \hline
         1024                     & 1407.65                             & 948.70                                \\
         \hline
         1280                     & 2632.17                             & 528.31                                \\
         \hline
         1536                     & 4889.38                             & 1753.68                               \\
         \hline
         1792                     & 7963.17                             & 1956.31                               \\
         \hline
         2048                     & 26496.56                            & 19573.49                              \\
         \hline
         2304                     & 17474.20                            & 4640.64                               \\
         \hline
         2560                     & 28872.98                            & 22779.53                              \\
         \hline
         2816                     & 32588.44                            & 10419.45                              \\
         \hline
         3072                     & 93145.27                            & 70182.88                              \\ [1ex]
         \hline
         3328                     & 87606.52                            & 28659.00                              \\ [1ex]
         \hline
         3584                     & 160394.68                           & 101793.75                             \\ [1ex]
         \hline
         3840                     & 181057.62                           & 60536.71                              \\ [1ex]
         \hline
         4096                     & 268178.54                           & 176223.93                             \\ [1ex]
         \hline
     \end{tabular}
     \captionof{table}{Time taken for serial and parallel algorithm}
 \end{center}

 From the results shown above, the average time taken for the serial algorithm is $57093.49ms$  and $31259.91ms$ for the parallel algorithm.
 The speedup is \textbf{45.25\%} calculated using the formula: $$\frac{|avg\;time_{parallel} - avg\;time_{serial}|}{avg\;time_{serial}} \cdot 100\%$$.

 That might not seem like a very bizarre speedup from the percentage but it still makes a big difference with an average of extra \textbf{25.83s} of overhead while using the serial algorithm.
 That said, the speedup depends heavily on the matrix size $n$. For example, when $n = 256$ the parallel
 algorithm is faster than the serial algorithm by \textbf{6} times. However, when $n = 2048$ the parallel algorithm is only faster than the serial algorithm by \textbf{1.35} times.
\end{section}

\begin{section}{Increasing number of threads}
 To investigate out how different number of threads affect the execution time, I ran the parallel algorithms with different number of threads and plotted the combined graph below.
 Note that to change the number of threads with OpenMP, just run the binary with an extra \texttt{OMP\_NUM\_THREADS} environment variable.

 \begin{center}
     \includegraphics*[width=12cm]{images/benchmark_combined_openmp.png}
     \captionof{figure}{Matrix norm benchmark with different number of threads}
 \end{center}

 From the figure above, we can see that there is still justifiable speedup from increasing the number of threads from 4 to 8 but after 8 threads,
 the speedup in execution time is basically negligible. One possible cause for this
 is the bottleneck of thread synchronisation using the \texttt{\#pragma omp critical} macro in the calculation of matrix norm. The code
 for this can be found in the source \texttt{include/parallel.h} line 95. The reason being this region is mutual exclusive and only accessible
 by one thread at a time hence no matter how many number of threads we increase, the extra threads will be blocked here waiting for their turn
 to enter the critical region.

\end{section}

\end{document}