\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry} 
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{mathtools}
\usepackage{titlesec}

\titleformat*{\section}{\large\bfseries}

\begin{document}

\begin{center}
    {\LARGE Parallel matrix norms using pthreads} \\[0.6cm]

    Lee Kai Yang (23205838) \\
    \texttt{\small kai.y.lee@ucdconnect.ie} \\[0.3cm]

    \small November 12, 2023
\end{center}

\begin{section}{Introduction}
 The aim of this experiemnt is to discover the difference between the serial and parallel algorithm for computing matrix norms. The
 parallel algorithm was imlemented using \textbf{pthreads} and the benchmark was ran on a machine with 8 x Intel(R) Xeon(R) E5-2620 v3 @ 2.40GHz processors.
 The program uses the number of processors as the number of threads hence the results for parallel algorithm shown in following sections uses 8 threads.

 All the matrix multiplication algorithms used in this experiemnt are written manually without using any third-party dependencies both for
 the serial algorithm and the parallel algorithm.
\end{section}

\begin{section}{Dependence of program execution time on matrix size}
 Since the matrix size $n$ must be divisible by the number of threads, the benchmark was ran with $n$ ranging from
 $128$ to $1792$ with a step of $128$. Figures below show the execution time for the serial and parallel algorithm with
 increasing matrix size $n$.

 \begin{center}
     \begin{minipage}{0.48\linewidth}
         \includegraphics*[width=8cm]{images/benchmark_serial.png}
         \captionof{figure}{Matrix norm using serial algorithm}
     \end{minipage}
     \begin{minipage}{0.48\linewidth}
         \includegraphics*[width=8cm]{images/benchmark_parallel.png}
         \captionof{figure}{Matrix norm using pthreads}
     \end{minipage}
 \end{center}

 From the results above, we can deduce that as matrix size $n$ increases, execution time increases. This is true for both cases because
 the number of computation needed increases.

\end{section}

\pagebreak

\begin{section}{Speedup of parallel algorithm over serial algorithm}
 To further investigate on the speedup of the parallel algorithm over the serial algorithm, Figure 3 below shows the plot of the execution time
 for the serial algorithm and the parallel algorithm on the same graph. Moreover, Table 1 below includes the execution time for both algorithms
 for different matrix size $n$.

 \begin{center}
     \includegraphics*[width=12cm]{images/benchmark_combined.png}
     \captionof{figure}{Matrix norm benchmark}
 \end{center}

 \begin{center}
     \begin{tabular}{|c | c | c|}
         \hline
         \textbf{Matrix size (n)} & \textbf{Time taken for serial (ms)} & \textbf{Time taken for parallel (ms)} \\ [0.5ex]
         \hline
         128                      & 0.97                                & 10.83                                 \\
         \hline
         256                      & 5.66                                & 33.25                                 \\
         \hline
         384                      & 15.36                               & 65.15                                 \\
         \hline
         512                      & 34.5                                & 117.55                                \\
         \hline
         640                      & 62.42                               & 196.83                                \\
         \hline
         768                      & 117.13                              & 317.01                                \\
         \hline
         896                      & 169.87                              & 480.37                                \\
         \hline
         1024                     & 240.73                              & 3257.47                               \\
         \hline
         1152                     & 340.48                              & 3223.21                               \\
         \hline
         1280                     & 462.89                              & 6557.70                               \\
         \hline
         1408                     & 608.636                             & 8467.80                               \\ [1ex]
         \hline
         1536                     & 778.77                              & 11587.90                              \\ [1ex]
         \hline
         1664                     & 985.34                              & 13826.90                              \\ [1ex]
         \hline
         1792                     & 1217.72                             & 18577.88                              \\ [1ex]
         \hline
     \end{tabular}
     \captionof{table}{Time taken for serial and parallel algorithm}
 \end{center}

 %  \begin{center}
 %      \begin{minipage}{0.48\linewidth}
 %          \includegraphics*[width=8cm]{images/blas_non_block.png}
 %          \captionof{figure}{Non-blocked BLAS routine}
 %      \end{minipage}
 %      \begin{minipage}{0.48\linewidth}
 %          \includegraphics*[width=8cm]{images/atlas_block_1024.png}
 %          \captionof{figure}{Blocked \textit{ijk} ATLAS (block size 1024)}
 %      \end{minipage}
 %  \end{center}

 From the results shown above, the average time taken for the non-blocked algorithm is $4970.56$ms and $3546.13$ms for the blocked algorithm.
 The speedup is $40\%$ calculated using the formula: $$\frac{(avg\;time_{blocked} - avg\;time_{non-blocked})}{avg\;time_{non-blocked}} \cdot 100\%$$.
\end{section}

\end{document}